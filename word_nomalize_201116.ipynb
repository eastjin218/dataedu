{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사용자 사전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "etc_dictionary = {\n",
    "        '2 30대': '이삼십대',\n",
    "        '20~30대': '이삼십대',\n",
    "        '20, 30대': '이십대 삼십대',\n",
    "        '1+1': '원플러스원',\n",
    "        '3에서 6개월인': '3개월에서 육개월인',\n",
    "}\n",
    "\n",
    "english_dictionary = {\n",
    "        'Devsisters': '데브시스터즈',\n",
    "        'track': '트랙',\n",
    "\n",
    "        # krbook\n",
    "        'LA': '엘에이',\n",
    "        'LG': '엘지',\n",
    "        'KOREA': '코리아',\n",
    "        'JSA': '제이에스에이',\n",
    "        'PGA': '피지에이',\n",
    "        'GA': '지에이',\n",
    "        'idol': '아이돌',\n",
    "        'KTX': '케이티엑스',\n",
    "        'AC': '에이씨',\n",
    "        'DVD': '디비디',\n",
    "        'US': '유에스',\n",
    "        'CNN': '씨엔엔',\n",
    "        'LPGA': '엘피지에이',\n",
    "        'P': '피',\n",
    "        'L': '엘',\n",
    "        'T': '티',\n",
    "        'B': '비',\n",
    "        'C': '씨',\n",
    "        'BIFF': '비아이에프에프',\n",
    "        'GV': '지비',\n",
    "\n",
    "        # JTBC\n",
    "        'IT': '아이티',\n",
    "        'IQ': '아이큐',\n",
    "        'JTBC': '제이티비씨',\n",
    "        'trickle down effect': '트리클 다운 이펙트',\n",
    "        'trickle up effect': '트리클 업 이펙트',\n",
    "        'down': '다운',\n",
    "        'up': '업',\n",
    "        'FCK': '에프씨케이',\n",
    "        'AP': '에이피',\n",
    "        'WHERETHEWILDTHINGSARE': '',\n",
    "        'Rashomon Effect': '',\n",
    "        'O': '오',\n",
    "        'OO': '오오',\n",
    "        'B': '비',\n",
    "        'GDP': '지디피',\n",
    "        'CIPA': '씨아이피에이',\n",
    "        'YS': '와이에스',\n",
    "        'Y': '와이',\n",
    "        'S': '에스',\n",
    "        'JTBC': '제이티비씨',\n",
    "        'PC': '피씨',\n",
    "        'bill': '빌',\n",
    "        'Halmuny': '하모니', #####\n",
    "        'X': '엑스',\n",
    "        'SNS': '에스엔에스',\n",
    "        'ability': '어빌리티',\n",
    "        'shy': '',\n",
    "        'CCTV': '씨씨티비',\n",
    "        'IT': '아이티',\n",
    "        'the tenth man': '더 텐쓰 맨', ####\n",
    "        'L': '엘',\n",
    "        'PC': '피씨',\n",
    "        'YSDJJPMB': '', ########\n",
    "        'Content Attitude Timing': '컨텐트 애티튜드 타이밍',\n",
    "        'CAT': '캣',\n",
    "        'IS': '아이에스',\n",
    "        'SNS': '에스엔에스',\n",
    "        'K': '케이',\n",
    "        'Y': '와이',\n",
    "        'KDI': '케이디아이',\n",
    "        'DOC': '디오씨',\n",
    "        'CIA': '씨아이에이',\n",
    "        'PBS': '피비에스',\n",
    "        'D': '디',\n",
    "        'PPropertyPositionPowerPrisonP'\n",
    "        'S': '에스',\n",
    "        'francisco': '프란시스코',\n",
    "        'I': '아이',\n",
    "        'III': '아이아이', ######\n",
    "        'No joke': '노 조크',\n",
    "        'BBK': '비비케이',\n",
    "        'LA': '엘에이',\n",
    "        'Don': '',\n",
    "        't worry be happy': ' 워리 비 해피',\n",
    "        'NO': '엔오', #####\n",
    "        'it was our sky': '잇 워즈 아워 스카이',\n",
    "        'it is our sky': '잇 이즈 아워 스카이', ####\n",
    "        'NEIS': '엔이아이에스', #####\n",
    "        'IMF': '아이엠에프',\n",
    "        'apology': '어폴로지',\n",
    "        'humble': '험블',\n",
    "        'M': '엠',\n",
    "        'Nowhere Man': '노웨어 맨',\n",
    "        'The Tenth Man': '더 텐쓰 맨',\n",
    "        'PBS': '피비에스',\n",
    "        'BBC': '비비씨',\n",
    "        'MRJ': '엠알제이',\n",
    "        'CCTV': '씨씨티비',\n",
    "        'Pick me up': '픽 미 업',\n",
    "        'DNA': '디엔에이',\n",
    "        'UN': '유엔',\n",
    "        'STOP': '스탑', #####\n",
    "        'PRESS': '프레스', #####\n",
    "        'not to be': '낫 투비',\n",
    "        'Denial': '디나이얼',\n",
    "        'G': '지',\n",
    "        'IMF': '아이엠에프',\n",
    "        'GDP': '지디피',\n",
    "        'JTBC': '제이티비씨',\n",
    "        'Time flies like an arrow': '타임 플라이즈 라이크 언 애로우',\n",
    "        'DDT': '디디티',\n",
    "        'AI': '에이아이',\n",
    "        'Z': '제트',\n",
    "        'OECD': '오이씨디',\n",
    "        'N': '앤',\n",
    "        'A': '에이',\n",
    "        'MB': '엠비',\n",
    "        'EH': '이에이치',\n",
    "        'IS': '아이에스',\n",
    "        'TV': '티비',\n",
    "        'MIT': '엠아이티',\n",
    "        'KBO': '케이비오',\n",
    "        'I love America': '아이 러브 아메리카',\n",
    "        'SF': '에스에프',\n",
    "        'Q': '큐',\n",
    "        'KFX': '케이에프엑스',\n",
    "        'PM': '피엠',\n",
    "        'Prime Minister': '프라임 미니스터',\n",
    "        'Swordline': '스워드라인',\n",
    "        'TBS': '티비에스',\n",
    "        'DDT': '디디티',\n",
    "        'CS': '씨에스',\n",
    "        'Reflecting Absence': '리플렉팅 앱센스',\n",
    "        'PBS': '피비에스',\n",
    "        'Drum being beaten by everyone': '드럼 빙 비튼 바이 에브리원',\n",
    "        'negative pressure': '네거티브 프레셔',\n",
    "        'F': '에프',\n",
    "        'KIA': '기아',\n",
    "        'FTA': '에프티에이',\n",
    "        'Que sais-je': '',\n",
    "        'UFC': '유에프씨',\n",
    "        'P': '피',\n",
    "        'DJ': '디제이',\n",
    "        'Chaebol': '채벌',\n",
    "        'BBC': '비비씨',\n",
    "        'OECD': '오이씨디',\n",
    "        'BC': '삐씨',\n",
    "        'C': '씨',\n",
    "        'B': '씨',\n",
    "        'KY': '케이와이',\n",
    "        'K': '케이',\n",
    "        'CEO': '씨이오',\n",
    "        'YH': '와이에치',\n",
    "        'IS': '아이에스',\n",
    "        'who are you': '후 얼 유',\n",
    "        'Y': '와이',\n",
    "        'The Devils Advocate': '더 데빌즈 어드보카트',\n",
    "        'YS': '와이에스',\n",
    "        'so sorry': '쏘 쏘리',\n",
    "        'Santa': '산타',\n",
    "        'Big Endian': '빅 엔디안',\n",
    "        'Small Endian': '스몰 엔디안',\n",
    "        'Oh Captain My Captain': '오 캡틴 마이 캡틴',\n",
    "        'AIB': '에이아이비',\n",
    "        'K': '케이',\n",
    "        'PBS': '피비에스',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 한글 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import ast\n",
    "import json\n",
    "from jamo import hangul_to_jamo, h2j, j2h\n",
    "\n",
    "# from .ko_dictionary import english_dictionary, etc_dictionary\n",
    "\n",
    "PAD = '_'\n",
    "EOS = '~'\n",
    "PUNC = '!\\'(),-.:;?'\n",
    "SPACE = ' '\n",
    "\n",
    "JAMO_LEADS = \"\".join([chr(_) for _ in range(0x1100, 0x1113)])\n",
    "JAMO_VOWELS = \"\".join([chr(_) for _ in range(0x1161, 0x1176)])\n",
    "JAMO_TAILS = \"\".join([chr(_) for _ in range(0x11A8, 0x11C3)])\n",
    "\n",
    "VALID_CHARS = JAMO_LEADS + JAMO_VOWELS + JAMO_TAILS + PUNC + SPACE\n",
    "ALL_SYMBOLS = PAD + EOS + VALID_CHARS\n",
    "\n",
    "char_to_id = {c: i for i, c in enumerate(ALL_SYMBOLS)}\n",
    "id_to_char = {i: c for i, c in enumerate(ALL_SYMBOLS)}\n",
    "\n",
    "quote_checker = \"\"\"([`\"'＂“‘])(.+?)([`\"'＂”’])\"\"\"\n",
    "\n",
    "def is_lead(char):\n",
    "    return char in JAMO_LEADS\n",
    "\n",
    "def is_vowel(char):\n",
    "    return char in JAMO_VOWELS\n",
    "\n",
    "def is_tail(char):\n",
    "    return char in JAMO_TAILS\n",
    "\n",
    "def get_mode(char):\n",
    "    if is_lead(char):\n",
    "        return 0\n",
    "    elif is_vowel(char):\n",
    "        return 1\n",
    "    elif is_tail(char):\n",
    "        return 2\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def _get_text_from_candidates(candidates):\n",
    "    if len(candidates) == 0:\n",
    "        return \"\"\n",
    "    elif len(candidates) == 1:\n",
    "        return _jamo_char_to_hcj(candidates[0])\n",
    "    else:\n",
    "        return j2h(**dict(zip([\"lead\", \"vowel\", \"tail\"], candidates)))\n",
    "\n",
    "def jamo_to_korean(text):\n",
    "    text = h2j(text)\n",
    "\n",
    "    idx = 0\n",
    "    new_text = \"\"\n",
    "    candidates = []\n",
    "\n",
    "    while True:\n",
    "        if idx >= len(text):\n",
    "            new_text += _get_text_from_candidates(candidates)\n",
    "            break\n",
    "\n",
    "        char = text[idx]\n",
    "        mode = get_mode(char)\n",
    "\n",
    "        if mode == 0:\n",
    "            new_text += _get_text_from_candidates(candidates)\n",
    "            candidates = [char]\n",
    "        elif mode == -1:\n",
    "            new_text += _get_text_from_candidates(candidates)\n",
    "            new_text += char\n",
    "            candidates = []\n",
    "        else:\n",
    "            candidates.append(char)\n",
    "\n",
    "        idx += 1\n",
    "    return new_text\n",
    "\n",
    "num_to_kor = {\n",
    "        '0': '영',\n",
    "        '1': '일',\n",
    "        '2': '이',\n",
    "        '3': '삼',\n",
    "        '4': '사',\n",
    "        '5': '오',\n",
    "        '6': '육',\n",
    "        '7': '칠',\n",
    "        '8': '팔',\n",
    "        '9': '구',\n",
    "}\n",
    "\n",
    "unit_to_kor1 = {\n",
    "        '%': ' 퍼센트 ',\n",
    "        'cm': ' 센치미터 ',\n",
    "        'mm': ' 밀리미터 ',\n",
    "        'km': ' 킬로미터 ',\n",
    "        'kg': ' 킬로그람 ',\n",
    "        '@': ' 골뱅이 ',\n",
    "}\n",
    "unit_to_kor2 = {\n",
    "        'm': ' 미터 ',\n",
    "}\n",
    "\n",
    "def compare_sentence_with_jamo(text1, text2):\n",
    "    return h2j(text1) != h2j(text)\n",
    "\n",
    "def tokenize(text, as_id=False):\n",
    "    # jamo package에 있는 hangul_to_jamo를 이용하여 한글 string을 초성/중성/종성으로 나눈다.\n",
    "    text = normalize(text)\n",
    "    tokens = list(hangul_to_jamo(text)) # '존경하는'  --> ['ᄌ', 'ᅩ', 'ᆫ', 'ᄀ', 'ᅧ', 'ᆼ', 'ᄒ', 'ᅡ', 'ᄂ', 'ᅳ', 'ᆫ', '~']\n",
    "\n",
    "    if as_id:\n",
    "        return [char_to_id[token] for token in tokens] + [char_to_id[EOS]]\n",
    "    else:\n",
    "        return [token for token in tokens] + [EOS]\n",
    "\n",
    "def tokenizer_fn(iterator):\n",
    "    return (token for x in iterator for token in tokenize(x, as_id=False))\n",
    "\n",
    "def normalize(text):\n",
    "    text = text.strip()\n",
    "\n",
    "    text = re.sub('\\(\\d+일\\)', '', text)\n",
    "    text = re.sub('\\([⺀-⺙⺛-⻳⼀-⿕々〇〡-〩〸-〺〻㐀-䶵一-鿃豈-鶴侮-頻並-龎]+\\)', '', text)\n",
    "\n",
    "    text = normalize_with_dictionary(text, etc_dictionary)\n",
    "    text = normalize_english(text)\n",
    "#     text = re.sub('[a-zA-Z]+', normalize_upper, text)\n",
    "\n",
    "    text = normalize_quote(text)\n",
    "    text = normalize_number(text)\n",
    "\n",
    "    return text\n",
    "\n",
    "def normalize_with_dictionary(text, dic):\n",
    "    if any(key in text for key in dic.keys()):\n",
    "        pattern = re.compile('|'.join(re.escape(key) for key in dic.keys()))\n",
    "        return pattern.sub(lambda x: dic[x.group()], text)\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "def normalize_english(text):\n",
    "    def fn(m):\n",
    "        word = m.group()\n",
    "        if word in english_dictionary:\n",
    "            return english_dictionary.get(word)\n",
    "        else:\n",
    "            return word\n",
    "\n",
    "    text = re.sub(\"([A-Za-z]+)\", fn, text)\n",
    "    return text\n",
    "\n",
    "def normalize_quote(text):\n",
    "    def fn(found_text):\n",
    "        from nltk import sent_tokenize # NLTK doesn't along with multiprocessing\n",
    "\n",
    "        found_text = found_text.group()\n",
    "        unquoted_text = found_text[1:-1]\n",
    "\n",
    "        sentences = sent_tokenize(unquoted_text)\n",
    "        return \" \".join([\"'{}'\".format(sent) for sent in sentences])\n",
    "\n",
    "    return re.sub(quote_checker, fn, text)\n",
    "\n",
    "number_checker = \"([+-]?\\d[\\d,]*)[\\.]?\\d*\"\n",
    "count_checker = \"(시|명|가지|살|마리|포기|송이|수|톨|통|점|개|벌|척|채|다발|그루|자루|줄|켤레|그릇|잔|마디|상자|사람|곡|병|판|종류)\"\n",
    "\n",
    "def normalize_number(text):\n",
    "    text = normalize_with_dictionary(text, unit_to_kor1)\n",
    "    text = normalize_with_dictionary(text, unit_to_kor2)\n",
    "    text = re.sub('[0-9]{6}[-][0-9]{7}', lambda m: stringNumber(m.group()), text)\n",
    "    text = pre_custom(text)\n",
    "    text = re.sub(number_checker + count_checker,\n",
    "            lambda x: number_to_korean(x, True), text)\n",
    "    text = re.sub(number_checker,\n",
    "            lambda x: number_to_korean(x, False), text)\n",
    "    return text\n",
    "\n",
    "num_to_kor1 = [\"\"] + list(\"일이삼사오육칠팔구\")\n",
    "num_to_kor2 = [\"\"] + list(\"만억조경해\")\n",
    "num_to_kor3 = [\"\"] + list(\"십백천\")\n",
    "\n",
    "count_to_kor1 = [\"\"] + [\"한\",\"두\",\"세\",\"네\",\"다섯\",\"여섯\",\"일곱\",\"여덟\",\"아홉\"]\n",
    "\n",
    "count_tenth_dict = {\n",
    "        \"십\": \"열\",\n",
    "        \"두십\": \"스물\",\n",
    "        \"세십\": \"서른\",\n",
    "        \"네십\": \"마흔\",\n",
    "        \"다섯십\": \"쉰\",\n",
    "        \"여섯십\": \"예순\",\n",
    "        \"일곱십\": \"일흔\",\n",
    "        \"여덟십\": \"여든\",\n",
    "        \"아홉십\": \"아흔\",\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def number_to_korean(num_str, is_count=False):\n",
    "    if is_count:\n",
    "        num_str, unit_str = num_str.group(1), num_str.group(2)\n",
    "    else:\n",
    "        num_str, unit_str = num_str.group(), \"\"\n",
    "    \n",
    "    num_str = num_str.replace(',', '')\n",
    "    num = ast.literal_eval(num_str)\n",
    "\n",
    "    if num == 0:\n",
    "        return \"영\"\n",
    "\n",
    "    check_float = num_str.split('.')\n",
    "    if len(check_float) == 2:\n",
    "        digit_str, float_str = check_float\n",
    "    elif len(check_float) >= 3:\n",
    "        raise Exception(\" [!] Wrong number format\")\n",
    "    else:\n",
    "        digit_str, float_str = check_float[0], None\n",
    "\n",
    "    if is_count and float_str is not None:\n",
    "        raise Exception(\" [!] `is_count` and float number does not fit each other\")\n",
    "\n",
    "    digit = int(digit_str)\n",
    "\n",
    "    if digit_str.startswith(\"-\"):\n",
    "        digit, digit_str = abs(digit), str(abs(digit))\n",
    "\n",
    "    kor = \"\"\n",
    "    size = len(str(digit))\n",
    "    tmp = []\n",
    "\n",
    "    for i, v in enumerate(digit_str, start=1):\n",
    "        v = int(v)\n",
    "\n",
    "        if v != 0:\n",
    "            if is_count:\n",
    "                tmp += count_to_kor1[v]\n",
    "            else:\n",
    "                tmp += num_to_kor1[v]\n",
    "\n",
    "            tmp += num_to_kor3[(size - i) % 4]\n",
    "\n",
    "        if (size - i) % 4 == 0 and len(tmp) != 0:\n",
    "            kor += \"\".join(tmp)\n",
    "            tmp = []\n",
    "            kor += num_to_kor2[int((size - i) / 4)]\n",
    "\n",
    "    if is_count:\n",
    "        if kor.startswith(\"한\") and len(kor) > 1:\n",
    "            kor = kor[1:]\n",
    "\n",
    "        if any(word in kor for word in count_tenth_dict):\n",
    "            kor = re.sub(\n",
    "                    '|'.join(count_tenth_dict.keys()),\n",
    "                    lambda x: count_tenth_dict[x.group()], kor)\n",
    "\n",
    "    if not is_count and kor.startswith(\"일\") and len(kor) > 1:\n",
    "        kor = kor[1:]\n",
    "\n",
    "    if float_str is not None:\n",
    "        kor += \"쩜 \"\n",
    "        kor += re.sub('\\d', lambda x: num_to_kor[x.group()], float_str)\n",
    "\n",
    "    if num_str.startswith(\"+\"):\n",
    "        kor = \"플러스 \" + kor\n",
    "    elif num_str.startswith(\"-\"):\n",
    "        kor = \"마이너스 \" + kor\n",
    "\n",
    "    return kor + unit_str\n",
    "\n",
    "\n",
    "def Eng2han(text):\n",
    "    upper_to_kor = {'A': '에이','B': '비','C': '씨','D': '디','E': '이', 'F': '에프', 'G': '지', 'H': '에이치', 'I': '아이', 'J': '제이', 'K': '케이', 'L': '엘', 'M': '엠', 'N': '엔',\n",
    "            'O': '오', 'P': '피', 'Q': '큐','R': '알', 'S': '에스', 'T': '티', 'U': '유','V': '브이','W': '더블유','X': '엑스','Y': '와이','Z': '지'}\n",
    "    tmp_text = []\n",
    "    for i in text:\n",
    "        i = i.upper()\n",
    "        if i in upper_to_kor:\n",
    "            tmp_text.append(upper_to_kor[i])\n",
    "        else:\n",
    "            tmp_text.append(i)\n",
    "    return ''.join(tmp_text)\n",
    "\n",
    "\n",
    "def pre_custom(text):\n",
    "    ## 사용자 변화 \n",
    "    text = re.sub('''['|\"|“|”|’|‘|]''','',text)\n",
    "    text = re.sub(r'(\\d)-([a-zA-Z])', r'\\1 다시 \\2', text)\n",
    "    text = re.sub(r'([a-zA-Z])-(\\d)', r'\\1 다시 \\2', text)\n",
    "    text = re.sub(r'([a-zA-Z])-([가-힣])', r'\\1 다시 \\2', text)\n",
    "    text = re.sub(r'([a-zA-Z])–([a-zA-Z])', r'\\1 다시 \\2', text)\n",
    "    text = re.sub(r'([가-힣])-([가-힣])', r'\\1  다시 \\2', text)\n",
    "    text = re.sub(r'([가-힣])–([가-힣])', r'\\1  다시 \\2', text)\n",
    "    text = re.sub(r'([가-힣])=([가-힣])', r'\\1은 \\2', text)\n",
    "    text = re.sub(r'([가-힣]) = ([가-힣])', r'\\1은 \\2', text)\n",
    "    text = re.sub(r'([가-힣]) - ([가-힣])', r'\\1  다시 \\2', text)\n",
    "    text = re.sub(r'([가-힣]) – ([가-힣])', r'\\1  다시 \\2', text)\n",
    "    text = re.sub(r'([가-힣]) – (\\d)', r'\\1  다시 \\2', text)\n",
    "    text = re.sub(r'([가-힣]) - (\\d)', r'\\1  다시 \\2', text)\n",
    "    text = re.sub(r'(\\d)-([가-힣])', r'\\1  다시 \\2', text)\n",
    "    text = re.sub(r'([가-힣])-(\\d)', r'\\1  다시 \\2', text)\n",
    "    text = re.sub(r'(\\d)\\.(\\d)', r'\\1 점\\2', text)\n",
    "    text = re.sub(r'(\\d)(\\d)(\\d)-(\\d)(\\d)(\\d)(\\d)', r'\\1\\2\\3 다시 \\4\\5\\6\\7', text)\n",
    "    text = re.sub(r'([a-zA-Z])\\.([a-zA-Z])', r'\\1 점 \\2', text)\n",
    "    text = re.sub('://', ' 땡땡 슬러쉬 슬러쉬 ', text)\n",
    "    text = re.sub('www.', ' 더블유더블유더블유 점 ', text)\n",
    "    text = text.replace('③', '삼 ')\n",
    "    text = text.replace('②', '이 ')\n",
    "    text = text.replace('①', '일 ')\n",
    "    text = text.replace('④', '사 ')\n",
    "    text = text.replace('⑤', '오 ')\n",
    "    text = text.replace('⑥', '육 ')\n",
    "    text = text.replace('⑦', '칠 ')\n",
    "    text = text.replace('⑧', '팔 ')\n",
    "    text = text.replace('⑨', '구 ')\n",
    "    text = text.replace('無', '무 ')\n",
    "    return text\n",
    "\n",
    "def stringNumber(text):\n",
    "    num_to_kor = {'0': '영','1': '일','2': '이', '3': '삼','4': '사','5': '오','6': '육','7': '칠','8': '팔', '9': '구'}\n",
    "    tmp_text = []\n",
    "    for i in text:\n",
    "        if i in num_to_kor:\n",
    "            tmp_text.append(num_to_kor[i])\n",
    "        else:\n",
    "            tmp_text.append(i)\n",
    "    return ''.join(tmp_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스무 살에 최고의 인기 둘리 인터뷰요리 보고 조리 봐도 귀여운 아기 공룡 둘리가 광고 모델로 변신해 화제다 올해로 스무 살 성인이 된 둘리는 주민등록번호 팔삼영사이이 다시 일일팔오육영영 까지 있는 엄연한 부천시민 대부분의 캐릭터가 반짝인기를 끌다 사라지는데 비해 둘리의 인기는 나이가 들수록 높아지고 있다 둘리는 그 이유를 멈추지 않고 끊임없이 변신하는 자세 때문이 아닐까요 라고 말했다 이 성인이 된 뒤에도 여전히 사랑받고 있는 둘리를 만나보았다 자동차에서 펜션까지 인기모델 둘리는 요즘 기아자동차의 카니발Ⅱ 광고 모델로 맹활약 중이다 둘리 덕분에 한달에 최고 천이백대가 더 팔려 사람들을 놀라게 했다 이에 대해 어린 시절 저를 보고 자란 세대들이 이제 자동차를 사는 소비자로 자란 것 같아요 제가 워낙 친근한 인상이잖아요 이런 가치에도 둘리는 여전히 겸손하다 너무 추켜세우지 마세요 쑥스러워요 아직 할 일이 더 많거든요 실제로 둘리의 활약은 끝이 없다 한글을 가르쳐 주는 사이트가 있고 과학에 대한 호기심을 풀어주는 책의 주인공으로도 활동중이다 둘리 친구들과 하룻밤을 지낼 수 있는 펜션까지 나왔다 소아암 병동의 캐릭터로도 나서 아이들에게 희망과 용기를 주고 있다 연봉 이십억원 넘는 유명 인사 둘리의 활발한 활동으로 몸값이 치솟고 있다 둘리는 저와 친구들인 마이콜 도우너 또치 희동이의 모습을 담은 완구 문구 의류 게임 팬시용품을 비롯해 전자제품과 음료 생활용품까지 천오백여종에 달하는 둘리 상품이 나와 있다며 자랑했다 둘리는 자기 얼굴과 이름을 빌려주고 받는 돈 로열티 만 따져도 한 해에 이십억원에 이른다고 한다 둘리의 고향은 서울 쌍문동 이십년 만에 그는 연봉 이십억원의 유명 인사로 입지전적인 성공을 거두었고 많은 사람들에게 희망을 심어주고 있다 사면에 이어져요 월드스타 될거예요 둘리의 이십년을 한마디로 표현하면 변신의 연속이다 둘리가 태어난 것은 이십년 전인 천구백팔십삼년 만화 잡지를 통해 세상과 처음으로 만났다 인쇄 만화는 티비용 시리즈 천구백팔십칠 팔십팔년 로 만들어졌는데 첫 번째 주인공이 둘리였다 천구백구십육년에 극장용 장편 애니메이션의 주인공이 돼 그해 관객 성적 사위에 올랐고 좋은 만화영화상 대상을 받기도 했다 이후 만화 캐릭터로는 세계 최초로 유엔아동기금 카드의 후견인 천구백구십칠 구십팔년 이 됐고 크리스마스 씰 이천이년 을 통해 많은 사람들에게 사랑 나눔을 몸소 실천하고 있다 작지만 큰 공룡을 꿈꾸며 이천일년 어린이 경제신문 에서 김수정 아빠를 직접 만났다고 들었어요 그 때도 말했지만 이제는 해외로 나갈 때라고 봐요 둘리가 밝힌 야심찬 꿈이다 더 넓은 세상에 대한민국 토종 캐릭터를 알리겠습니다 둘리는 이미 해외에도 많은 팬을 거느리고 있다 극장용 애니메이션은 이십오만 달러에 독일에 수출 구십구년 됐고 만화영화는 중국 인도네시아 등지로 나가 외화를 벌어들이고 있다 둘리는 이제 큰 세계시장에서 작지만 큰 공룡으로 새로운 꿈을 불태우고 있다 끝으로 둘리는 가장 자랑스러운 일이 무엇이냐는 질문에 부천 송내역 앞에 만들어진 둘리의 거리죠 얼마나 자랑스러운지 몰라요 여러분도 자기 이름으로 된 길이 있다고 생각해 보세요 가문의 영광입니다라고 말했다 박정현 기자 씨알이이피 골뱅이 이씨오엔오아이 점 씨오 점 케이알 어경이\n"
     ]
    }
   ],
   "source": [
    "import os , glob\n",
    "text_file = 'C:/Users/dataedu09/Documents/이동진/과제/데이터바우처/이코노아이/mecab_data/헤드경제_59.txt'\n",
    "with open(text_file, 'r',encoding='utf-8') as f:\n",
    "    tmp = f.read()[10:]\n",
    "    text = ' '.join(tmp.split( )) \n",
    "text1= normalize(text)\n",
    "text1 = re.sub('''[.|?|,|:|'|\"|“|”|’|]''',' ',text1)\n",
    "text1 = re.sub(\"[●△,■·#/\\▲〉▼?:^$.*★◆▶▣◇★\\♥◈○:〈▷☞\\\"～※~&ㆍ!』→\\\\‘|\\[\\]\\<\\>`\\'…》]\",' ',text1) \n",
    "text1 = re.sub('\\)|\\(', ' ', text1)\n",
    "text1 = Eng2han(text1)\n",
    "text1 = ' '.join(text1.split())\n",
    "print(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'8'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-360f922b5082>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'둘리는 주민등록번호(830422-1185600)까지 있는 엄연한 부천시민.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtmp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstringNumber\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-73-53002665c6dc>\u001b[0m in \u001b[0;36mstringNumber\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m    319\u001b[0m     \u001b[0mnum_t_kor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'0'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'영'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'1'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'일'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'2'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'이'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'3'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'삼'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'4'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'사'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'5'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'오'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'6'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'육'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'7'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'칠'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'8'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'팔'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'9'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'구'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnum_t_kor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m         \u001b[0mkor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'|'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_t_kor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcount_tenth_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mkor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36msub\u001b[1;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[1;32m--> 192\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-73-53002665c6dc>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    319\u001b[0m     \u001b[0mnum_t_kor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'0'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'영'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'1'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'일'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'2'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'이'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'3'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'삼'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'4'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'사'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'5'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'오'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'6'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'육'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'7'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'칠'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'8'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'팔'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'9'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'구'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnum_t_kor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m         \u001b[0mkor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'|'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_t_kor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcount_tenth_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mkor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '8'"
     ]
    }
   ],
   "source": [
    "text ='둘리는 주민등록번호(830422-1185600)까지 있는 엄연한 부천시민.'\n",
    "tmp=stringNumber(text)\n",
    "print(tmp)\n",
    "print(type(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
